in Dockerfile replace
   FROM pytorch/pytorch:1.10.0-cuda11.3-cudnn8-runtime
with
   pytorch/pytorch:1.6.0-cuda10.1-cudnn7-runtime
to see complaint about NVIDIA RTX A6000 with CUDA capability sm_86 is not compatible with the current PyTorch installation.

john@john-trx40-designare:/Disk2/Documents/GitHub/NCCL-WARN-Failed-to-open-libibverbs$ sh run.sh 
Building bug
Sending build context to Docker daemon  108.5kB
Step 1/6 : FROM pytorch/pytorch:1.6.0-cuda10.1-cudnn7-runtime
1.6.0-cuda10.1-cudnn7-runtime: Pulling from pytorch/pytorch
23884877105a: Pull complete 
bc38caa0f5b9: Pull complete 
2910811b6c42: Pull complete 
36505266dcc6: Pull complete 
3472d01858ba: Pull complete 
4a98b57681ff: Pull complete 
f3b419d1e6d5: Pull complete 
Digest: sha256:9c3aa4653f6fb6590acf7f49115735be3c3272f4fa79e5da7c96a2c901631352
Status: Downloaded newer image for pytorch/pytorch:1.6.0-cuda10.1-cudnn7-runtime
 ---> 6a2d656bcf94
Step 2/6 : RUN pip install pytorch-lightning==1.5.10
 ---> Running in 856b77234769
Collecting pytorch-lightning==1.5.10
  Downloading pytorch_lightning-1.5.10-py3-none-any.whl (527 kB)
Collecting future>=0.17.1
  Downloading future-0.18.2.tar.gz (829 kB)
Collecting setuptools==59.5.0
  Downloading setuptools-59.5.0-py3-none-any.whl (952 kB)
Collecting tensorboard>=2.2.0
  Downloading tensorboard-2.8.0-py3-none-any.whl (5.8 MB)
Requirement already satisfied: numpy>=1.17.2 in /opt/conda/lib/python3.7/site-packages (from pytorch-lightning==1.5.10) (1.18.5)
Collecting pyDeprecate==0.3.1
  Downloading pyDeprecate-0.3.1-py3-none-any.whl (10 kB)
Collecting typing-extensions
  Downloading typing_extensions-4.1.1-py3-none-any.whl (26 kB)
Requirement already satisfied: PyYAML>=5.1 in /opt/conda/lib/python3.7/site-packages (from pytorch-lightning==1.5.10) (5.3.1)
Collecting torchmetrics>=0.4.1
  Downloading torchmetrics-0.7.2-py3-none-any.whl (397 kB)
Collecting fsspec[http]!=2021.06.0,>=2021.05.0
  Downloading fsspec-2022.2.0-py3-none-any.whl (134 kB)
Collecting packaging>=17.0
  Downloading packaging-21.3-py3-none-any.whl (40 kB)
Requirement already satisfied: tqdm>=4.41.0 in /opt/conda/lib/python3.7/site-packages (from pytorch-lightning==1.5.10) (4.46.0)
Collecting torch>=1.7.*
  Downloading torch-1.10.2-cp37-cp37m-manylinux1_x86_64.whl (881.9 MB)
Collecting werkzeug>=0.11.15
  Downloading Werkzeug-2.0.3-py3-none-any.whl (289 kB)
Collecting grpcio>=1.24.3
  Downloading grpcio-1.44.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.3 MB)
Collecting protobuf>=3.6.0
  Downloading protobuf-3.19.4-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)
Collecting tensorboard-plugin-wit>=1.6.0
  Downloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)
Requirement already satisfied: wheel>=0.26 in /opt/conda/lib/python3.7/site-packages (from tensorboard>=2.2.0->pytorch-lightning==1.5.10) (0.34.2)
Requirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard>=2.2.0->pytorch-lightning==1.5.10) (2.23.0)
Collecting google-auth-oauthlib<0.5,>=0.4.1
  Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)
Collecting google-auth<3,>=1.6.3
  Downloading google_auth-2.6.0-py2.py3-none-any.whl (156 kB)
Collecting absl-py>=0.4
  Downloading absl_py-1.0.0-py3-none-any.whl (126 kB)
Collecting tensorboard-data-server<0.7.0,>=0.6.0
  Downloading tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)
Collecting markdown>=2.6.8
  Downloading Markdown-3.3.6-py3-none-any.whl (97 kB)
Collecting aiohttp; extra == "http"
  Downloading aiohttp-3.8.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)
Collecting pyparsing!=3.0.5,>=2.0.2
  Downloading pyparsing-3.0.7-py3-none-any.whl (98 kB)
Requirement already satisfied: six>=1.5.2 in /opt/conda/lib/python3.7/site-packages (from grpcio>=1.24.3->tensorboard>=2.2.0->pytorch-lightning==1.5.10) (1.14.0)
Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard>=2.2.0->pytorch-lightning==1.5.10) (1.25.8)
Requirement already satisfied: chardet<4,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard>=2.2.0->pytorch-lightning==1.5.10) (3.0.4)
Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard>=2.2.0->pytorch-lightning==1.5.10) (2020.6.20)
Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard>=2.2.0->pytorch-lightning==1.5.10) (2.9)
Collecting requests-oauthlib>=0.7.0
  Downloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)
Collecting pyasn1-modules>=0.2.1
  Downloading pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)
Collecting cachetools<6.0,>=2.0.0
  Downloading cachetools-5.0.0-py3-none-any.whl (9.1 kB)
Collecting rsa<5,>=3.1.4; python_version >= "3.6"
  Downloading rsa-4.8-py3-none-any.whl (39 kB)
Collecting importlib-metadata>=4.4; python_version < "3.10"
  Downloading importlib_metadata-4.11.2-py3-none-any.whl (17 kB)
Collecting async-timeout<5.0,>=4.0.0a3
  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)
Collecting yarl<2.0,>=1.0
  Downloading yarl-1.7.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (271 kB)
Collecting charset-normalizer<3.0,>=2.0
  Downloading charset_normalizer-2.0.12-py3-none-any.whl (39 kB)
Collecting attrs>=17.3.0
  Downloading attrs-21.4.0-py2.py3-none-any.whl (60 kB)
Collecting frozenlist>=1.1.1
  Downloading frozenlist-1.3.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (144 kB)
Collecting multidict<7.0,>=4.5
  Downloading multidict-6.0.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (94 kB)
Collecting aiosignal>=1.1.2
  Downloading aiosignal-1.2.0-py3-none-any.whl (8.2 kB)
Collecting asynctest==0.13.0; python_version < "3.8"
  Downloading asynctest-0.13.0-py3-none-any.whl (26 kB)
Collecting oauthlib>=3.0.0
  Downloading oauthlib-3.2.0-py3-none-any.whl (151 kB)
Collecting pyasn1<0.5.0,>=0.4.6
  Downloading pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)
Collecting zipp>=0.5
  Downloading zipp-3.7.0-py3-none-any.whl (5.3 kB)
Building wheels for collected packages: future
  Building wheel for future (setup.py): started
  Building wheel for future (setup.py): finished with status 'done'
  Created wheel for future: filename=future-0.18.2-py3-none-any.whl size=491058 sha256=341c6dcfeedd18f641026bee86825878987c112ced7a2dae4bd671497f3eacfa
  Stored in directory: /root/.cache/pip/wheels/56/b0/fe/4410d17b32f1f0c3cf54cdfb2bc04d7b4b8f4ae377e2229ba0
Successfully built future
Installing collected packages: future, setuptools, werkzeug, grpcio, protobuf, tensorboard-plugin-wit, oauthlib, requests-oauthlib, pyasn1, pyasn1-modules, cachetools, rsa, google-auth, google-auth-oauthlib, absl-py, tensorboard-data-server, zipp, typing-extensions, importlib-metadata, markdown, tensorboard, pyDeprecate, pyparsing, packaging, torch, torchmetrics, async-timeout, multidict, yarl, charset-normalizer, attrs, frozenlist, aiosignal, asynctest, aiohttp, fsspec, pytorch-lightning
  Attempting uninstall: setuptools
    Found existing installation: setuptools 46.4.0.post20200518
    Uninstalling setuptools-46.4.0.post20200518:
      Successfully uninstalled setuptools-46.4.0.post20200518
  Attempting uninstall: torch
    Found existing installation: torch 1.6.0
    Uninstalling torch-1.6.0:
      Successfully uninstalled torch-1.6.0
Successfully installed absl-py-1.0.0 aiohttp-3.8.1 aiosignal-1.2.0 async-timeout-4.0.2 asynctest-0.13.0 attrs-21.4.0 cachetools-5.0.0 charset-normalizer-2.0.12 frozenlist-1.3.0 fsspec-2022.2.0 future-0.18.2 google-auth-2.6.0 google-auth-oauthlib-0.4.6 grpcio-1.44.0 importlib-metadata-4.11.2 markdown-3.3.6 multidict-6.0.2 oauthlib-3.2.0 packaging-21.3 protobuf-3.19.4 pyDeprecate-0.3.1 pyasn1-0.4.8 pyasn1-modules-0.2.8 pyparsing-3.0.7 pytorch-lightning-1.5.10 requests-oauthlib-1.3.1 rsa-4.8 setuptools-59.5.0 tensorboard-2.8.0 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 torch-1.10.2 torchmetrics-0.7.2 typing-extensions-4.1.1 werkzeug-2.0.3 yarl-1.7.2 zipp-3.7.0
Removing intermediate container 856b77234769
 ---> 91082c7b90fa
Step 3/6 : WORKDIR /src
 ---> Running in 2719fbd98cd3
Removing intermediate container 2719fbd98cd3
 ---> 5455cdc0c58c
Step 4/6 : COPY ./bug-demo.py ./
 ---> 54062f1c5943
Step 5/6 : COPY ./collect_env.py ./
 ---> d354c8ed05ff
Step 6/6 : CMD python ./bug-demo.py
 ---> Running in 04bf9cab07b6
Removing intermediate container 04bf9cab07b6
 ---> b0b76ddd6297
Successfully built b0b76ddd6297
Successfully tagged bug:latest
Recreating bug_bug_1 ... done
Attaching to bug_bug_1
9920512it [00:01, 9371931.75it/s]                              
32768it [00:00, 252568.99it/s]           
1654784it [00:00, 4175088.52it/s]                             
8192it [00:00, 66486.72it/s]            
bug_1  | /opt/conda/lib/python3.7/site-packages/torchvision/datasets/mnist.py:469: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ../torch/csrc/utils/tensor_numpy.cpp:189.)
bug_1  |   return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)
bug_1  | GPU available: True, used: True
bug_1  | TPU available: False, using: 0 TPU cores
bug_1  | IPU available: False, using: 0 IPUs
bug_1  | Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to /src/MNIST/raw/train-images-idx3-ubyte.gz
bug_1  | Extracting /src/MNIST/raw/train-images-idx3-ubyte.gz to /src/MNIST/raw
bug_1  | Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to /src/MNIST/raw/train-labels-idx1-ubyte.gz
bug_1  | Extracting /src/MNIST/raw/train-labels-idx1-ubyte.gz to /src/MNIST/raw
bug_1  | Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to /src/MNIST/raw/t10k-images-idx3-ubyte.gz
bug_1  | Extracting /src/MNIST/raw/t10k-images-idx3-ubyte.gz to /src/MNIST/raw
bug_1  | Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to /src/MNIST/raw/t10k-labels-idx1-ubyte.gz
bug_1  | Extracting /src/MNIST/raw/t10k-labels-idx1-ubyte.gz to /src/MNIST/raw
bug_1  | Processing...
bug_1  | Done!
bug_1  | ****************************
bug_1  | torch.cuda.device_count:2
bug_1  | ****************************
bug_1  | Collecting environment information...
bug_1  | PyTorch version: 1.10.2+cu102
bug_1  | Is debug build: False
bug_1  | CUDA used to build PyTorch: 10.2
bug_1  | ROCM used to build PyTorch: N/A
bug_1  | OS: Ubuntu 18.04.4 LTS (x86_64)
bug_1  | GCC version: Could not collect
bug_1  | Clang version: Could not collect
bug_1  | CMake version: Could not collect
bug_1  | Libc version: glibc-2.10
bug_1  | Python version: 3.7.7 (default, May  7 2020, 21:25:33)  [GCC 7.3.0] (64-bit runtime)
bug_1  | Python platform: Linux-5.4.0-100-generic-x86_64-with-debian-buster-sid
bug_1  | Is CUDA available: True
bug_1  | CUDA runtime version: Could not collect
bug_1  | GPU models and configuration: 
bug_1  | GPU 0: NVIDIA RTX A6000
bug_1  | GPU 1: NVIDIA RTX A6000
bug_1  | 
bug_1  | Nvidia driver version: 510.47.03
bug_1  | cuDNN version: Could not collect
bug_1  | HIP runtime version: N/A
bug_1  | MIOpen runtime version: N/A
bug_1  | Is XNNPACK available: True
bug_1  | Versions of relevant libraries:
bug_1  | [pip3] numpy==1.18.5
bug_1  | [pip3] pytorch-lightning==1.5.10
bug_1  | [pip3] torch==1.10.2
bug_1  | [pip3] torchmetrics==0.7.2
bug_1  | [pip3] torchvision==0.7.0
bug_1  | [conda] blas                      1.0                         mkl  
bug_1  | [conda] cudatoolkit               10.1.243             h6bb024c_0  
bug_1  | [conda] mkl                       2020.1                      217  
bug_1  | [conda] mkl-service               2.3.0            py37he904b0f_0  
bug_1  | [conda] mkl_fft                   1.1.0            py37h23d657b_0  
bug_1  | [conda] mkl_random                1.1.1            py37h0573a6f_0  
bug_1  | [conda] numpy                     1.18.5           py37ha1c710e_0  
bug_1  | [conda] numpy-base                1.18.5           py37hde5b4d6_0  
bug_1  | [conda] pytorch-lightning         1.5.10                   pypi_0    pypi
bug_1  | [conda] torch                     1.10.2                   pypi_0    pypi
bug_1  | [conda] torchmetrics              0.7.2                    pypi_0    pypi
bug_1  | [conda] torchvision               0.7.0                py37_cu101    pytorch
bug_1  | ****************************
bug_1  | ****************************
bug_1  | torch.cuda.device_count:2
bug_1  | ****************************
bug_1  | /opt/conda/lib/python3.7/site-packages/pytorch_lightning/trainer/configuration_validator.py:120: UserWarning: You passed in a `val_dataloader` but have no `validation_step`. Skipping val loop.
bug_1  |   rank_zero_warn("You passed in a `val_dataloader` but have no `validation_step`. Skipping val loop.")
bug_1  | initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/2
bug_1  | Collecting environment information...
bug_1  | PyTorch version: 1.10.2+cu102
bug_1  | Is debug build: False
bug_1  | CUDA used to build PyTorch: 10.2
bug_1  | ROCM used to build PyTorch: N/A
bug_1  | OS: Ubuntu 18.04.4 LTS (x86_64)
bug_1  | GCC version: Could not collect
bug_1  | Clang version: Could not collect
bug_1  | CMake version: Could not collect
bug_1  | Libc version: glibc-2.10
bug_1  | Python version: 3.7.7 (default, May  7 2020, 21:25:33)  [GCC 7.3.0] (64-bit runtime)
bug_1  | Python platform: Linux-5.4.0-100-generic-x86_64-with-debian-buster-sid
bug_1  | Is CUDA available: True
bug_1  | CUDA runtime version: Could not collect
bug_1  | GPU models and configuration: 
bug_1  | GPU 0: NVIDIA RTX A6000
bug_1  | GPU 1: NVIDIA RTX A6000
bug_1  | 
bug_1  | Nvidia driver version: 510.47.03
bug_1  | cuDNN version: Could not collect
bug_1  | HIP runtime version: N/A
bug_1  | MIOpen runtime version: N/A
bug_1  | Is XNNPACK available: True
bug_1  | Versions of relevant libraries:
bug_1  | [pip3] numpy==1.18.5
bug_1  | [pip3] pytorch-lightning==1.5.10
bug_1  | [pip3] torch==1.10.2
bug_1  | [pip3] torchmetrics==0.7.2
bug_1  | [pip3] torchvision==0.7.0
bug_1  | [conda] blas                      1.0                         mkl  
bug_1  | [conda] cudatoolkit               10.1.243             h6bb024c_0  
bug_1  | [conda] mkl                       2020.1                      217  
bug_1  | [conda] mkl-service               2.3.0            py37he904b0f_0  
bug_1  | [conda] mkl_fft                   1.1.0            py37h23d657b_0  
bug_1  | [conda] mkl_random                1.1.1            py37h0573a6f_0  
bug_1  | [conda] numpy                     1.18.5           py37ha1c710e_0  
bug_1  | [conda] numpy-base                1.18.5           py37hde5b4d6_0  
bug_1  | [conda] pytorch-lightning         1.5.10                   pypi_0    pypi
bug_1  | [conda] torch                     1.10.2                   pypi_0    pypi
bug_1  | [conda] torchmetrics              0.7.2                    pypi_0    pypi
bug_1  | [conda] torchvision               0.7.0                py37_cu101    pytorch
bug_1  | ****************************
bug_1  | initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/2
bug_1  | ----------------------------------------------------------------------------------------------------
bug_1  | distributed_backend=nccl
bug_1  | All distributed processes registered. Starting with 2 processes
bug_1  | ----------------------------------------------------------------------------------------------------
bug_1  | 
bug_1  | 
bug_1  | ccff84b525b0:7:7 [0] enqueue.cc:102 NCCL WARN Cuda failure 'invalid device function'
bug_1  | 
bug_1  | ccff84b525b0:7:7 [0] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
bug_1  | NCCL version 2.10.3+cuda10.2
bug_1  | 
bug_1  | ccff84b525b0:75:75 [1] enqueue.cc:102 NCCL WARN Cuda failure 'invalid device function'
bug_1  | 
bug_1  | ccff84b525b0:75:75 [1] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
bug_1  | 
bug_1  | ccff84b525b0:7:7 [0] enqueue.cc:300 NCCL WARN Cuda failure 'invalid device function'
bug_1  | 
bug_1  | ccff84b525b0:75:75 [1] enqueue.cc:300 NCCL WARN Cuda failure 'invalid device function'
bug_1  | /opt/conda/lib/python3.7/site-packages/torch/cuda/__init__.py:143: UserWarning: 
bug_1  | NVIDIA RTX A6000 with CUDA capability sm_86 is not compatible with the current PyTorch installation.
bug_1  | The current PyTorch install supports CUDA capabilities sm_37 sm_50 sm_60 sm_70.
bug_1  | If you want to use the NVIDIA RTX A6000 GPU with PyTorch, please check the instructions at https://pytorch.org/get-started/locally/
bug_1  | 
bug_1  |   warnings.warn(incompatible_device_warn.format(device_name, capability, " ".join(arch_list), device_name))
bug_1  | /opt/conda/lib/python3.7/site-packages/pytorch_lightning/plugins/training_type/ddp.py:510: UserWarning: Error handling mechanism for deadlock detection is uninitialized. Skipping check.
bug_1  |   rank_zero_warn("Error handling mechanism for deadlock detection is uninitialized. Skipping check.")
bug_1  | /opt/conda/lib/python3.7/site-packages/torch/cuda/__init__.py:143: UserWarning: 
bug_1  | NVIDIA RTX A6000 with CUDA capability sm_86 is not compatible with the current PyTorch installation.
bug_1  | The current PyTorch install supports CUDA capabilities sm_37 sm_50 sm_60 sm_70.
bug_1  | If you want to use the NVIDIA RTX A6000 GPU with PyTorch, please check the instructions at https://pytorch.org/get-started/locally/
bug_1  | 
bug_1  |   warnings.warn(incompatible_device_warn.format(device_name, capability, " ".join(arch_list), device_name))
bug_1  | Traceback (most recent call last):
bug_1  |   File "./bug-demo.py", line 53, in <module>
bug_1  |     main()
bug_1  |   File "./bug-demo.py", line 49, in main
bug_1  |     trainer.fit(autoencoder, DataLoader(train), DataLoader(val))
bug_1  |   File "/opt/conda/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py", line 741, in fit
bug_1  |     self._fit_impl, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path
bug_1  |   File "/opt/conda/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py", line 685, in _call_and_handle_interrupt
bug_1  |     return trainer_fn(*args, **kwargs)
bug_1  |   File "/opt/conda/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py", line 777, in _fit_impl
bug_1  |     self._run(model, ckpt_path=ckpt_path)
bug_1  |   File "/opt/conda/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py", line 1138, in _run
bug_1  |     self._call_setup_hook()  # allow user to setup lightning_module in accelerator environment
bug_1  |   File "/opt/conda/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py", line 1435, in _call_setup_hook
bug_1  |     self.training_type_plugin.barrier("pre_setup")
bug_1  |   File "/opt/conda/lib/python3.7/site-packages/pytorch_lightning/plugins/training_type/ddp.py", line 403, in barrier
bug_1  |     torch.distributed.barrier(device_ids=self.determine_ddp_device_ids())
bug_1  |   File "/opt/conda/lib/python3.7/site-packages/torch/distributed/distributed_c10d.py", line 2709, in barrier
bug_1  |     work = default_pg.barrier(opts=opts)
bug_1  | RuntimeError: NCCL error in: ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:45, unhandled cuda error, NCCL version 21.0.3
bug_1  | ncclUnhandledCudaError: Call to CUDA function failed.
bug_1  | Traceback (most recent call last):
bug_1  |   File "/src/bug-demo.py", line 53, in <module>
bug_1  |     main()
bug_1  |   File "/src/bug-demo.py", line 49, in main
bug_1  |     trainer.fit(autoencoder, DataLoader(train), DataLoader(val))
bug_1  |   File "/opt/conda/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py", line 741, in fit
bug_1  |     self._fit_impl, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path
bug_1  |   File "/opt/conda/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py", line 685, in _call_and_handle_interrupt
bug_1  |     return trainer_fn(*args, **kwargs)
bug_1  |   File "/opt/conda/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py", line 777, in _fit_impl
bug_1  |     self._run(model, ckpt_path=ckpt_path)
bug_1  |   File "/opt/conda/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py", line 1138, in _run
bug_1  |     self._call_setup_hook()  # allow user to setup lightning_module in accelerator environment
bug_1  |   File "/opt/conda/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py", line 1435, in _call_setup_hook
bug_1  |     self.training_type_plugin.barrier("pre_setup")
bug_1  |   File "/opt/conda/lib/python3.7/site-packages/pytorch_lightning/plugins/training_type/ddp.py", line 403, in barrier
bug_1  |     torch.distributed.barrier(device_ids=self.determine_ddp_device_ids())
bug_1  |   File "/opt/conda/lib/python3.7/site-packages/torch/distributed/distributed_c10d.py", line 2709, in barrier
bug_1  |     work = default_pg.barrier(opts=opts)
bug_1  | RuntimeError: NCCL error in: ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:45, unhandled cuda error, NCCL version 21.0.3
bug_1  | ncclUnhandledCudaError: Call to CUDA function failed.
bug_bug_1 exited with code 1
